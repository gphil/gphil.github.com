<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">
    <title>gphil's blog - All posts</title>
    <link href="http://gphil.net/rss.xml" rel="self" />
    <link href="http://gphil.net" />
    <id>http://gphil.net/rss.xml</id>
    <author>
        <name>Greg Phillips</name>
        <email>gap023@gmail.com</email>
    </author>
    <updated>2013-06-07T00:00:00Z</updated>
    <entry>
    <title>Thoughts on Clojure vs. Ruby for Startups</title>
    <link href="http://gphil.net/posts/2013-06-07-thoughts-on-clojure-versus-ruby-for-startups.html" />
    <id>http://gphil.net/posts/2013-06-07-thoughts-on-clojure-versus-ruby-for-startups.html</id>
    <published>2013-06-07T00:00:00Z</published>
    <updated>2013-06-07T00:00:00Z</updated>
    <summary type="html"><![CDATA[<p>At <a href="https://kwelia.com">Kwelia</a> we’re building our platform using both Ruby and Clojure. As of today, our web application is a Rails app but we do a lot of backend data processing in Clojure. I personally prefer programming in Clojure to programming in Ruby, and some days I wish we had more Clojure than Ruby in our codebase. I don’t think we’ll be switching from Rails any time soon, but we may try to encapsulate more business logic behind Clojure web services in the future.</p>
<p>When we started building our product (and I still think this is true today–although it’s less true now) it was faster and easier to get a production-ready web application up using Ruby on Rails. One of the best features of Rails in my opinion is that it makes a lot of design decisions for you and that it has pretty sane defaults for the most part. This ends up saving a lot of time up front, which is critical for a start up that wants to quickly validate an idea. There is also a lot of open source code available via RubyGems that replaces or expedites a lot of common web application development tasks. This is a one-two punch that’s pretty hard to beat in a start up context.</p>
<p>However, as the Clojure ecosystem matures it’s starting to chip away at the advantages that the Rails ecosystem offers. More and more quality libraries are being shipped to <a href="https://clojars.org">Clojars</a>, and informal conventions are starting to emerge regarding how to structure a web application in Clojure. I think the growth of both of these are critical for newcomers who want to get started on a Clojure webapp quickly. I’m optimistic that these trends will continue and Clojure will continue to become a better and better choice for new projects.</p>]]></summary>
</entry>
<entry>
    <title>Is It Possible to Securely Meter a Client-Facing API?</title>
    <link href="http://gphil.net/posts/2013-05-12-is-it-possible-to-securely-meter-a-javascript-api.html" />
    <id>http://gphil.net/posts/2013-05-12-is-it-possible-to-securely-meter-a-javascript-api.html</id>
    <published>2013-05-12T00:00:00Z</published>
    <updated>2013-05-12T00:00:00Z</updated>
    <summary type="html"><![CDATA[<p>Imagine that your business provides a paid API (or since you’re reading this blog, there’s a good chance it actually does), and you want to meter the number of calls to it so that you can bill the API consumers based on their usage.</p>
<p>The best way to do this is to provide a unique secret token to each consumer of the API. Then, you require that the consumer includes the secret token with each API call in order to authenticate that they are allowed to access the API. You can also measure the usage associated with each token. So long as these authentication tokens stay secret, so good.</p>
<p>But what about environments where the API consumer can’t keep their token secret? For example, consider a client-side JavaScript app or a native mobile app where the binary is provided to an untrusted tablet or phone. In both of these cases it is possible for a malicious third party to discover the secret token and authenticate to the API on the legitimate consumer’s behalf (by posing as the consumer using their token.) This is a pretty big issue. There’s basically no way around this if they API needs to be called from an untrusted source. (For more information on this, see <a href="http://www.schneier.com/essay-063.html">this essay</a>.)</p>
<p>It seems to me that the best you can do is to also log the IP address and the top-level domain that the request is originating from (if it’s available.) I think this must be what the <a href="https://developers.google.com/maps/documentation/javascript/reference">Google Maps JavaScript API</a> is doing, as they provide a metered service to client-side JavaScript apps without requiring a secret token. However, these identifiers can also be easily forged or changed by malicious consumers when limits are reached.</p>
<p>You could go a step further and look at the actual usage patterns of the API and decide which are legitimate and which are not based on the legitimate client’s historical usage of the API. But this would be a lot of effort, and would likely be prone to false positives.</p>
<p>I’m not a security expert (just a developer who strives to make secure software) so I don’t know if there are more or better techniques, but it seems like any API accessible from an environment that can be accessed by malicious third parties is susceptible.</p>
<p>It would be interesting to study how the aforementioned Google Maps API is enforcing its metering. Perhaps Google is just willing to accept some amount of unauthorized access? I would love to hear how existing APIs in this category cope with this problem.</p>]]></summary>
</entry>
<entry>
    <title>50 Percent Failure Rate</title>
    <link href="http://gphil.net/posts/2013-04-27-50-percent-failure-rate.html" />
    <id>http://gphil.net/posts/2013-04-27-50-percent-failure-rate.html</id>
    <published>2013-04-27T00:00:00Z</published>
    <updated>2013-04-27T00:00:00Z</updated>
    <summary type="html"><![CDATA[<p>Lately I’ve been reading <a href="http://www.amazon.com/gp/product/1935401009/ref=as_li_qf_sp_asin_tl?ie=UTF8&amp;camp=1789&amp;creative=9325&amp;creativeASIN=1935401009&amp;linkCode=as2&amp;tag=gphilsblog-20">The Principles of Product Development Flow</a> by Don Reinertsen. It describes a set of principles for conducting product development in an economically optimal fashion.</p>
<p>The principles in the book are aimed at product development “in the large.” The goal of the book is to empower product developers to make better decisions by quantifying the expected economic value of each decision faced when developing a product.</p>
<p>In my case, I’m developing a software product in a startup context (at <a href="https://kwelia.com">Kwelia</a>) and I’ve found that many of principles described in the book have been helpful in guiding our product development.</p>
<p>One of the principles stood out to me as particularly enlightening for a startup: when running an experiment with two outcomes, a 50% failure rate is optimal for generating information.</p>
<p>That’s because if something is certain to succeed or fail, there’s no reason to test it because you already know. If something is likely to fail, you’ll generate a lot of information if it doesn’t actually fail. But in the majority of instances it will indeed fail, and as such this experiment yields little information.</p>
<p>So, the optimal experiment for generating new information has a 50% failure rate. Programmers might recognize this principle from the binary search algorithm.</p>
<p>This principle underlies a lot of what we should be doing when de-risking startups. Binary questions such as “should we do this or not?” or “will that work?” are constantly arising as we generate new ideas.</p>
<p>Applying this principle, we should try to devise experiments that are much more likely to fail (50%) than we might intuitively think, if we want them to generate as much new information as possible.</p>]]></summary>
</entry>
<entry>
    <title>Loading US Census ACS Data into PostgreSQL</title>
    <link href="http://gphil.net/posts/2013-03-05-loading-us-census-acs-data-into-postgresql.html" />
    <id>http://gphil.net/posts/2013-03-05-loading-us-census-acs-data-into-postgresql.html</id>
    <published>2013-03-05T00:00:00Z</published>
    <updated>2013-03-05T00:00:00Z</updated>
    <summary type="html"><![CDATA[<p>Today I was looking into displaying data from the <a href="https://www.census.gov/acs/www/">US Census ACS</a> (the most recent being the 2011 5-year estimates) alongside our analytics at <a href="http://kwelia.com">Kwelia</a>. Unfortunately, this data is only available in a pretty strange format (spread across thousands of text files) that is not easily queried. So, I decided that the first order of business was to get the data loaded into a PostgreSQL database and work from there.</p>
<p>I googled around and found a few projects on GitHub that were built for the purpose of loading this data into PostgreSQL. I settled on <a href="https://github.com/leehach/census-postgres">this one</a>, which did most of what I needed.</p>
<p>However, I had to make a few changes because I only wanted to load the data for the census tract level and ignore the other geographies because we can aggregate everything up from the census tract level in our app. You can check out what I ended up with in <a href="https://github.com/gphil/census-postgres">my version</a>.</p>
<p>It took me a little while to figure this out on my own, so hopefuly this is helpful for other people trying to use this data. Even after loading the data it’s still fairly difficult to figure out what’s where, but at least it’s now in a format that’s easier to manipulate and query.</p>]]></summary>
</entry>
<entry>
    <title>Logging in Clojure</title>
    <link href="http://gphil.net/posts/2012-09-04-logging-in-clojure.html" />
    <id>http://gphil.net/posts/2012-09-04-logging-in-clojure.html</id>
    <published>2012-09-04T00:00:00Z</published>
    <updated>2012-09-04T00:00:00Z</updated>
    <summary type="html"><![CDATA[<p>At <a href="http://kwelia.com">Kwelia</a> we are using Clojure for some data integration and transformation tasks. As these tasks started to get more complex, what initially started as some short and somewhat disorganized scripts has now evolved into a larger project which organizes these tasks.</p>
<p>Recently, I wanted to configure a logging service for this project and I found that the process for doing so was not well documented, and I hit a few speedbumps along the way. So, I’ve decided to share what I found here.</p>
<p>After a little bit of research, I discovered <a href="https://github.com/clojure/tools.logging">clojure.tools.logging</a> which is a set of logging macros which delegate to one of many interchangeable logging frameworks. (From the README: “At runtime a specific implementation is selected from, in order, slf4j, Apache commons-logging, log4j, and finally java.util.logging.”)</p>
<p>So, my first stab at it was to just add clojure.tools.logging to my leiningen project and test it out as demonstrated in the README.</p>
<script src="https://gist.github.com/3625496.js"> </script>

<p>I intentionally didn’t try to add any logging backends yet, just to see what happened out of the box. When I tried logging something I got the following messages:</p>
<script src="https://gist.github.com/3625006.js?file=gistfile1.txt"></script>

<p>I figured that this meant that clojure.tools.logging was trying to use SLF4J as the above line quoted from the README suggested it would, but I hadn’t ever explicitly installed SLF4J so I decided to dig into that. Using “lein deps :tree” I found out that <a href="https://github.com/neotyk/http.async.client">http.async.client</a> (which we were already using in this project to integrate with some webservices) depended on it.</p>
<p>Since SLF4J appears itself to be a wrapper for multiple logging backends, and since I’ve used log4j in the past, I decided that I would point SLF4J to use log4j. (I also considered trying to use log4j directly, but I was dissuaded from doing so based on <a href="https://groups.google.com/d/msg/clojure-dev/H0scci72QQ0/ynVUsipwbkMJ">this conversation.</a>)</p>
<p>So I added log4j to my project.clj (the exclusions are optional dependencies not available in Clojars or Maven Central and I did not want to deal with obtaining them from other sources):</p>
<script src="https://gist.github.com/3625485.js"> </script>

<p>And put the following basic log4j configuration in my src/ directory (it can go anywhere on the CLASSPATH):</p>
<script src="https://gist.github.com/3624967.js"></script>

<p>Finally, I had to explicitly add the log4j adapter for SLF4J in order to get everything to link up.</p>
<script src="https://gist.github.com/3625561.js"> </script>

<p>After adding these dependencies and the log4j.properties configuration file, I was successfully able to use clojure.tools.logging to log to log4j via SLF4J.</p>
<p>Hopefully this is helpful to somebody else who’s trying to figure this out. I’m no expert in this domain, so if you think I did something wrong please let me know in the comments.</p>]]></summary>
</entry>
<entry>
    <title>Is the SQL "HAVING" Clause Strictly Necessary?</title>
    <link href="http://gphil.net/posts/2012-06-18-is-a-sql-having-clause-necessary.html" />
    <id>http://gphil.net/posts/2012-06-18-is-a-sql-having-clause-necessary.html</id>
    <published>2012-06-18T00:00:00Z</published>
    <updated>2012-06-18T00:00:00Z</updated>
    <summary type="html"><![CDATA[<p>The other day I was refactoring a SQL query containing a “HAVING” clause, and while I was thinking about that refactor, I realized that “HAVING” clauses can always in principle be reimplemented using a self-join to a subquery and a “WHERE” clause.</p>
<p>My “proof” of this is that you can always write a subquery using the grouping and aggregate that you wish to filter on, then join the outer query to it using the columns in the grouping, and then filter the outer query using based on the result of the joined-in aggregate from the subquery.</p>
<p>Consider the following example, which selects all the ice cream parlors in cities that have over 5 ice cream parlors:</p>
<script src="https://gist.github.com/3625695.js"> </script>

<p>This can be re-written as:</p>
<script src="https://gist.github.com/3625707.js"> </script>

<p>It seems that all “HAVING” queries could in principle be re-written this way, undermining an explicit need for the “HAVING” clause. However, I think there are some benefits to using the “HAVING” clause, even if you don’t necessarily need it to express your query.</p>
<p>The first and most obvious benefit of the “HAVING” clause is that the first query is shorter and easier to understand than the second query.</p>
<p>Another potential benefit of the “HAVING” clause is that depending on your database, there may be significant performance differences between these two approaches, although I haven’t really looked into this at all yet other than to check that these queries generate significantly different explain plans in PostgreSQL.</p>
<p>Finally, I’m not 100% sure if all possible use cases of a “HAVING” clause can be rewritten using this method (or similar), but I haven’t been able to come up with any counter-examples.</p>
<p>Does anyone know of any counter-examples that I’m missing, or have a more conclusive proof that all “HAVING” clauses can be re-written like this?</p>]]></summary>
</entry>
<entry>
    <title>Setting up a blog using Hakyll and GitHub</title>
    <link href="http://gphil.net/posts/2011-10-26-setting-up-a-blog-with-hakyll-and-github.html" />
    <id>http://gphil.net/posts/2011-10-26-setting-up-a-blog-with-hakyll-and-github.html</id>
    <published>2011-10-26T00:00:00Z</published>
    <updated>2011-10-26T00:00:00Z</updated>
    <summary type="html"><![CDATA[<p>I first discovered Haskell in 2008, and I remember even then being quite impressed by the quality of the <a href="http://haskell.org/haskellwiki/Haskell">community</a>, which has since grown substantially. There was enough buzz around it that I decided to jump in and try to <a href="http://haskell.org/haskellwiki/Tutorials">learn some Haskell</a>.</p>
<p>My first foray into Haskell (and functional programming in general) was hacking up some solutions to <a href="http://projecteuler.net/">Project Euler</a> problems in Haskell, and after solving just a few of them I noticed that the core Haskell paradigms (laziness, purity) really shifted my thinking about the practice of programming in general.</p>
<p>Since that initial discovery phase, I haven’t actually used Haskell much. I’ve learned quite a bit more about functional programming since then, but largely this has been through more thorough experimentation with Clojure over the last year or two.</p>
<p>I was recently reading a blog post by <a href="http://chrisdone.com/">Chris Done</a> that made the front page of Hacker News and caught my eye. The post discussed “value polymorphism” which reminded me how little that I actually know about Haskell, having just scratched the surface in my earlier exploration.</p>
<p>I also noticed that he was using <a href="http://jaspervdj.be/hakyll/index.html">Hakyll</a> as his blogging engine, and I figured that since I was planning to start this blog, and I was feeling like I wanted to get back into some Haskell coding, that I could kill two birds with one stone.</p>
<p>Here’s how I did it:</p>
<p>First, I downloaded and installed the <a href="http://hackage.haskell.org/platform/">Haskell Platform</a> for Mac OS X. I remember when trying to get Haskell set up in the past I always had a little bit of a hard time figuring it all out, but the Haskell Platform package has really improved that experience.</p>
<p>Next, I just ran:</p>
<pre><code> cabal install hakyll</code></pre>
<p>I was hoping this would just work out of the box but unfortunately, this failed with a compiler error when it tried to build the library regex-pcre-0.94.2:</p>
<pre><code> Wrap.hsc:143:18: error: pcre.h: No such file or directory</code></pre>
<p>I figured that I must be missing some regex library that didn’t come with the Haskell package, so after a little research I tried installing the “pcre” Homebrew package:</p>
<pre><code> brew install pcre</code></pre>
<p>Sure enough, that did the trick and a second crack at: “cabal install hakyll” finished without any further issues. I later found that this issue is covered in the Hakyll FAQ <a href="http://jaspervdj.be/hakyll/tutorials/faq.html#problem-with-regex-pcre-dependency-on-mac-os">here</a>.</p>
<p>The next step was to work through the tutorial on the hakyll site in order to understand some of the general concepts. I ran into another obstacle during this step, trying to compile of some of the example code. Fortunately, this was <a href="http://jaspervdj.be/hakyll/tutorials/faq.html#file-name-does-not-match-module-name-on-mac-os">also documented in the Hakyll FAQ</a> so I was able to quickly resolve it.</p>
<p>Once I had the lay of the land, I copied the tagblog/ folder out of the hakyll-examples project and into my own git project. From there, I edited the files in the css/ and templates/ directory to my liking. For the duration of this step, I kept the sample blog posts around so I could see how they looked as I changed the templates and styles.</p>
<p>As soon as the site was looking good, I removed the extraneous files from the Hakyll sample blog and build the site using the Hakyll compiler. Since everything is statically compiled into the _site/ directory, you can just turn this into it’s own git repo (you’ll have to add “/<em>site&quot; to your .gitignore if you want to put the rest of the project into git as well since that will be it’s own repo) and push it to a repository named &quot;your</em>github_acct.github.com” and <a href="http://pages.github.com/">github pages</a> will do the rest!</p>
<p>You can check out <a href="https://github.com/gphil">my github page</a> for the source.</p>]]></summary>
</entry>

</feed>
