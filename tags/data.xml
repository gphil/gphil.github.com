<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">
    <title>gphil's blog - Posts tagged data</title>
    <link href="http://gphil.net/tags/data.xml" rel="self" />
    <link href="http://gphil.net" />
    <id>http://gphil.net/tags/data.xml</id>
    <author>
        <name>Greg Phillips</name>
        <email>gap023@gmail.com</email>
    </author>
    <updated>2016-05-26T00:00:00Z</updated>
    <entry>
    <title>Explaining the 2017 Philadelphia Property Tax Assessment Changes</title>
    <link href="http://gphil.net/posts/2016-05-26-explaining-the-2017-philadelphia-property-tax-assessment-changes.html" />
    <id>http://gphil.net/posts/2016-05-26-explaining-the-2017-philadelphia-property-tax-assessment-changes.html</id>
    <published>2016-05-26T00:00:00Z</published>
    <updated>2016-05-26T00:00:00Z</updated>
    <summary type="html"><![CDATA[<p>The Philadelphia Office of Property Assessment (OPA) recently released their property tax assessments for the 2017 tax year. It’s been widely reported that these assessments <a href="http://planphilly.com/articles/2016/04/20/2017-property-tax-assessments-shift-more-value-to-land">shifted a substantial amount of value from building values to land values</a>, perhaps accurately reflecting <a href="http://planphilly.com/articles/2016/03/04/what-s-driving-philly-s-rising-land-values">growing land values</a> in the city.</p>
<p>More recently, the methodology behind this move has resulted in <a href="http://www.newsworks.org/index.php/essay-works/item/93495">some controversy</a> with the general consensus being that the new <b class="emphasis">2017 land values seem to be derived from previous building values rather than the from the fundamental underlying value of the land.</b></p>
<p>This is a problem for a number of reasons. For one, it is an inaccurate approach because the value of what is currently built (or not) on the land has nothing to do with the underlying land value. <b class="emphasis">If you are going to value the land based on the building, you might as well just only value the building.</b></p>
<p>Worse, this approach unfairly targets owners of properties with buildings having 10-year tax abatements, as that exemption pertains only to the building value and not to the land value of the property. Furthermore, these properties by have higher building values by definition (the amount of the abatement is proportional to the increased building assessment.) <b class="emphasis">In effect, the city is partially reneging on tax abatements.</b></p>
<p>Because I build real estate analytics products professionally, and because I own tax-abated property in the city of Philadelphia, I couldn’t help myself from doing a deeper dive into the data to see what actually transpired. It might take a little bit of patience to get through the full analysis that follows, but the short version is that the data shows that, for a subset of properties, the new 2017 land values appear to in fact be derived mainly from 2016 building values.</p>
<p>(By the way, I love digging into and discussing this kind of thing so I’m happy to answer any questions, offer advice, or just talk shop so please <script type="text/javascript">
<!--
h='&#x67;&#112;&#104;&#x69;&#108;&#46;&#110;&#x65;&#116;';a='&#64;';n='&#x67;&#112;&#104;&#x69;&#108;';e=n+a+h;
document.write('<a h'+'ref'+'="ma'+'ilto'+':'+e+'">'+'get in touch!'+'<\/'+'a'+'>');
// -->
</script><noscript>&#x67;&#x65;&#116;&#32;&#x69;&#110;&#32;&#116;&#x6f;&#x75;&#x63;&#104;&#x21;&#32;&#40;&#x67;&#112;&#104;&#x69;&#108;&#32;&#x61;&#116;&#32;&#x67;&#112;&#104;&#x69;&#108;&#32;&#100;&#x6f;&#116;&#32;&#110;&#x65;&#116;&#x29;</noscript>)</p>
<p>OK, here we go with the data stuff:</p>
<p>The <a href="https://www.opendataphilly.org/dataset/opa-property-assessments">2017 Philadelphia Property Tax Assessment</a> dataset contains comprehensive descriptive ownership and market value information for the 579,912 properties in the city of Philadelphia. All 578,276 properties from that dataset having tax assessments in both 2016 and 2017 are considered in this analysis. Of interest in this analysis are the following tax assessments:</p>
<table class="property-tax-definitions">
  <tr>
     <td class="emphasis">
Taxable Building
</td>
     <td>
Taxable value of the improvement
</td>
  </tr>
  <tr>
     <td class="emphasis">
Exempt Building
</td>
     <td>
Tax exemptions on the improvement
</td>
  </tr>
  <tr>
     <td class="emphasis">
Total Building
</td>
     <td>
Taxable Building + Exempt Building
</td>
  </tr>
  <tr>
     <td class="emphasis">
Taxable Land
</td>
     <td>
Taxable value of the land
</td>
  </tr>
  <tr>
     <td class="emphasis">
Exempt Land
</td>
     <td>
Tax exemptions on the land
</td>
  </tr>
  <tr>
     <td class="emphasis">
Total Land
</td>
     <td>
Taxable Land + Exempt Land
</td>
  </tr>
  <tr>
     <td class="emphasis">
Market Value
</td>
     <td>
Total Land + Total Building
</td>
  </tr>
</table>

<p>In 2017, the OPA adjusted the market value for only 4.5% of properties in this so there was not a major change in the total valuation of most properties (the proportion was a bit higher when you just look at residential properties but I wanted to look at the dataset as a whole.)</p>
<p>However, for vast majority of properties (79% of all properties) the market value was held constant and some amount was simply “shifted” between the component land and building values. For 54% of all properties, some amount was shifted from the land value to the building value and for 25% of all properties, some amount was shifted from the building value to the land value.</p>
<p>Based on this evidence, it appears the city’s goal was to rebalance the land and building components of the assessment without changing the assessment of the total market value. There was an overall focus on shifting more value to the land portion of the assessment, but there was movement in both directions.</p>
<p>On the surface, this seems like a pretty measured and reasonable approach: don’t worry too much about the total market values and try to get to a more accurate underlying the land/building split while shifting value to the land portion of the assessment which many observers have been calling out as undervalued for years.</p>
<p>However, when you dig deeper into the data this approach resulted in some peculiarities suggesting that what transpired was not just an objective re-evaluation of land values based on the fundamental value of the land, but rather a transfer of building value to land value based on the building value.</p>
<p>Looking at the dataset as a whole, building and land value do not appear to be correlated. (r<sup>2</sup> = ~.13 for both the 2016 and 2017 assessments.) This what one would expect, as the value of the underlying land intuitively should not necessarily be correlated with the value of what happens to be currently built on it. In practice, land value comes down to location and parcel size. However, despite the low overall correlation there actually is still a visible pattern (always check the scatter plot):</p>
<p><img src="/img/building_to_land_value_total_scatter.png" /></p>
<p>The above chart demonstrates that there actually is a relationship between building value and land value. The lack of observations upper-left quadrant of the cluster suggest that there are essentially no high land value, low building value assessments–at least not to the same extent that there are high building value, low land value assessments.</p>
<p>Because the OPA held the market value constant for the vast majority of properties, there was not much of an opportunity to change land values for properties with lower building values (e.g. there was not a lot of building value to shift for low-value buildings.) Given this observation, let’s look at the effect for just the properties that underwent a building-to-land value shift:</p>
<p><img src="/img/building_to_land_value_shifted_scatter.png" /></p>
<p>In this portion of the data, the correlation between 2016 building value to 2017 land value is immediately obvious (r<sup>2</sup>=.93) with a very strong linear relationship. This is a direct consequence of the 2017 assessment changes–In 2016, the building to land value correlation was r<sup>2</sup>=.74, and in 2017 it jumped up to r<sup>2</sup>=.90. In fact, the 2017 land assessments in this cohort can actually be better explained in terms of their previous building value than their previous land value (r<sup>2</sup>=.88) or the size of the parcel (r<sup>2</sup>=.11)!</p>
<p>Intentional or not, these assessments can be interpreted as unfairly targeting taxpayers owning properties having higher building values (e.g. those with tax abatements) rather than independent assessments of the underlying land.</p>
<p>This doesn’t matter too much in the context of properties without tax exemptions on the building, but owners of higher building value tax-abated properties in this set of properties will now have disproportionately higher tax bills, as part of their abatement was quite literally taken away when some of their building value was transferred to land value. In my opinion the effect of future tax abatements may be less pronounced if buyers become concerned that building value could again be shifted to land value in the same fashion.</p>
<p>I think the most concerning aspect of this approach (where building value is used a proxy for land value) is that it is divorced from the actual, real-world drivers of land value (location and size.) This is worrisome because if the assessment methodology used by the OPA is not predictable, it could be de-stabilizing and serve as a disincentive for investment in Philadelphia real estate by adding an unnecessary “future uncertain tax reassessment” risk.</p>
<p>At the end of the day, I’m actually a proponent of shifting more assessed value to land for a number of reasons, but I think the OPA did not take the right approach in these assessments. I would have not touched any of the building values (and hence tax abatements), then conducted an independent re-evaluation of the fundamental land values.</p>
<p>This approach is more difficult, and would affect a wider range of taxpayers than just 12,000 owners of tax abated properties, but it is the right way to go about fixing the problem of under-assessed land. Instead, by partially unraveling existing tax abatements to move more value to land, the City may have cost itself some future development.</p>
<p>The obvious remaining open question is, how were the 54% of “land-shifted” properties selected? The city has stated that <a href="http://www.philadelphiacontroller.org/media/press-releases/property-reassessments-could-add-30-million-in-new-revenues">12,000 of 15,000 tax-abated properties are in fact affected</a> so that’s a start. I might dive into this topic next if there is interest, but I’ve exhausted my side-project time budget on this for now. I love diving into this kind of stuff, so if you’re interested in more analysis, have feedback, questions about a particular property or area please <script type="text/javascript">
<!--
h='&#x67;&#112;&#104;&#x69;&#108;&#46;&#110;&#x65;&#116;';a='&#64;';n='&#x67;&#112;&#104;&#x69;&#108;';e=n+a+h;
document.write('<a h'+'ref'+'="ma'+'ilto'+':'+e+'">'+'drop me a line!'+'<\/'+'a'+'>');
// -->
</script><noscript>&#100;&#114;&#x6f;&#112;&#32;&#x6d;&#x65;&#32;&#x61;&#32;&#108;&#x69;&#110;&#x65;&#x21;&#32;&#40;&#x67;&#112;&#104;&#x69;&#108;&#32;&#x61;&#116;&#32;&#x67;&#112;&#104;&#x69;&#108;&#32;&#100;&#x6f;&#116;&#32;&#110;&#x65;&#116;&#x29;</noscript></p>]]></summary>
</entry>
<entry>
    <title>My Quantified Self Setup</title>
    <link href="http://gphil.net/posts/2013-08-31-my-quantified-self-setup.html" />
    <id>http://gphil.net/posts/2013-08-31-my-quantified-self-setup.html</id>
    <published>2013-08-31T00:00:00Z</published>
    <updated>2013-08-31T00:00:00Z</updated>
    <summary type="html"><![CDATA[<p>A few years ago, I didn’t keep track of any personal metrics, nor did I feel there was any need to. This has changed drastically since then: I now keep track of metrics pertaining to my work habits, career, exercise, diet and sleep. As others have observed before, I found that merely keeping track of these metrics has positively affected my focus, behavior and overall health. However, it didn’t happen overnight–it took a progression of deliberate incremental steps over time.</p>
<p>I started with <a href="https://www.rescuetime.com/">RescueTime</a> shortly after co-founding my startup, <a href="https://www.kwelia.com/">Kwelia</a>. Kwelia is my first venture, and I left a more structured software engineering job at an established company to start it. My initial motivation was that I didn’t want my work ethic to slip when my job became more self-directed. This didn’t happen for a number of reasons, but I think RescueTime’s tracking of all of my behavior on my computer certainly helped me stay focused. (I could really use RescueTime or a RescueTime-like for my iPhone as well–it seems like that’s where I waste the most time now, but I digress.)</p>
<p>After the initial success with RescueTime, I was thinking about how I could measure progress on more of a career and company development level. I came across this <a href="http://calnewport.com/blog/2013/04/08/deliberately-experimenting-with-deliberate-practice-looking-for-subjects-to-test-my-advice/">blog post</a> by <a href="http://calnewport.com">Cal Newport</a> announcing a class that would explore the notion of <a href="https://en.wikipedia.org/wiki/Practice_learning_method#Deliberate_practice">deliberate practice</a> in a career-development context, and my interest was piqued. I ended up taking the class, and the biggest take-away for me was the isolation of some key career metrics that I wanted to track. I won’t go into too much detail, but they all boiled to down to gaining more traction for <a href="https://kwelia.com/">Kwelia</a>, as well as for my personal brand via writing and tweeting more. I now periodically track these metrics manually in a small Emacs <a href="https://org-mode.org">org-mode</a> document. Just keeping track of a few rough measures of “traction” has inspired me to work harder to promote myself and my company.</p>
<p>The final piece of my current Quantified Self puzzle fell into place when my <a href="https://twitter.com/jessdabel">lovely, fitness-obsessed girlfriend</a> bought me a <a href="http://www.fitbit.com/">FitBit</a>. Initially, I thought I would just wear it and track my steps as a rough gauge of how much physical activity I was getting. However, I ended up going whole-hog and tracking my sleep, calories consumed and other fitness activity using their software as well. I’ve been doing this for almost a month now, and I’ve been losing weight and finding it easier to make healthier choices when it comes to my diet and exercise just by keeping track.</p>
<p>If there’s one lesson I’ve learned from all of this, it’s that you can initiate a tremendous amount of personal change just by starting to keep track of metrics in areas where you wish to improve. If you dutifully keep track of your past activity, you will naturally be more mindful of your goals when making decisions in the future. I underestimated the power of this phenomenon going into it, but now I’m slowly but surely becoming a quantified-self addict.</p>]]></summary>
</entry>
<entry>
    <title>Don't Get Lost in Big Data</title>
    <link href="http://gphil.net/posts/2013-08-01-dont-get-lost-in-big-data.html" />
    <id>http://gphil.net/posts/2013-08-01-dont-get-lost-in-big-data.html</id>
    <published>2013-08-01T00:00:00Z</published>
    <updated>2013-08-01T00:00:00Z</updated>
    <summary type="html"><![CDATA[<p>The value of data comes only when one can derive actionable insights from it. Accordingly, the primary aim of a big data project should be to convert big data into useful data.</p>
<p>However, it seems like a lot of big data projects lose sight of the this goal. I think the reason for this is that these projects quickly run into engineering challenges.</p>
<p>It’s easy to lose the forest for the trees when the focus shifts from the end goal (delivering value to stakeholders) to acheiving difficult intermediate goals (how are we going to efficiently process this data?)</p>
<p>I had this realization after I recently re-read <a href="http://www.crunchbase.com/person/dj-patil">DJ Patil’s</a> essay <a href="http://oreilly.com/data/radarreports/data-jujitsu.csp">Data Jujitsu</a>. The essay is so-named because it talks about how to work around the big engineering challenges that tend to crop up when working with large datasets, without meeting them head-on. I found that it really resonated with some of the findings I’ve had while working on <a href="https://kwelia.com">Kwelia</a>.</p>
<p>These types of “Data Jujitsu” strategies are critical for getting a big data project off the ground–not only because they help you avoid doing extra work, but also because they make it easier to stay focused on the real goal of delivering as much value as possible to the stakeholders of the project.</p>]]></summary>
</entry>
<entry>
    <title>Loading US Census ACS Data into PostgreSQL</title>
    <link href="http://gphil.net/posts/2013-03-05-loading-us-census-acs-data-into-postgresql.html" />
    <id>http://gphil.net/posts/2013-03-05-loading-us-census-acs-data-into-postgresql.html</id>
    <published>2013-03-05T00:00:00Z</published>
    <updated>2013-03-05T00:00:00Z</updated>
    <summary type="html"><![CDATA[<p>Today I was looking into displaying data from the <a href="https://www.census.gov/acs/www/">US Census ACS</a> (the most recent being the 2011 5-year estimates) alongside our analytics at <a href="http://kwelia.com">Kwelia</a>. Unfortunately, this data is only available in a pretty strange format (spread across thousands of text files) that is not easily queried. So, I decided that the first order of business was to get the data loaded into a PostgreSQL database and work from there.</p>
<p>I googled around and found a few projects on GitHub that were built for the purpose of loading this data into PostgreSQL. I settled on <a href="https://github.com/leehach/census-postgres">this one</a>, which did most of what I needed.</p>
<p>However, I had to make a few changes because I only wanted to load the data for the census tract level and ignore the other geographies because we can aggregate everything up from the census tract level in our app. You can check out what I ended up with in <a href="https://github.com/gphil/census-postgres">my version</a>.</p>
<p>It took me a little while to figure this out on my own, so hopefuly this is helpful for other people trying to use this data. Even after loading the data it’s still fairly difficult to figure out what’s where, but at least it’s now in a format that’s easier to manipulate and query.</p>]]></summary>
</entry>

</feed>
