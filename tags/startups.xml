<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">
    <title>gphil's blog - Posts tagged startups</title>
    <link href="http://gphil.net/tags/startups.xml" rel="self" />
    <link href="http://gphil.net" />
    <id>http://gphil.net/tags/startups.xml</id>
    <author>
        <name>Greg Phillips</name>
        <email>gap023@gmail.com</email>
    </author>
    <updated>2013-08-01T00:00:00Z</updated>
    <entry>
    <title>Don't Get Lost in Big Data</title>
    <link href="http://gphil.net/posts/2013-08-01-dont-get-lost-in-big-data.html" />
    <id>http://gphil.net/posts/2013-08-01-dont-get-lost-in-big-data.html</id>
    <published>2013-08-01T00:00:00Z</published>
    <updated>2013-08-01T00:00:00Z</updated>
    <summary type="html"><![CDATA[<p>The value of data comes only when one can derive actionable insights from it. Accordingly, the primary aim of a big data project should be to convert big data into useful data.</p>
<p>However, it seems like a lot of big data projects lose sight of the this goal. I think the reason for this is that these projects quickly run into engineering challenges.</p>
<p>It’s easy to lose the forest for the trees when the focus shifts from the end goal (delivering value to stakeholders) to acheiving difficult intermediate goals (how are we going to efficiently process this data?)</p>
<p>I had this realization after I recently re-read <a href="http://www.crunchbase.com/person/dj-patil">DJ Patil’s</a> essay <a href="http://oreilly.com/data/radarreports/data-jujitsu.csp">Data Jujitsu</a>. The essay is so-named because it talks about how to work around the big engineering challenges that tend to crop up when working with large datasets, without meeting them head-on. I found that it really resonated with some of the findings I’ve had while working on <a href="https://kwelia.com">Kwelia</a>.</p>
<p>These types of “Data Jujitsu” strategies are critical for getting a big data project off the ground–not only because they help you avoid doing extra work, but also because they make it easier to stay focused on the real goal of delivering as much value as possible to the stakeholders of the project.</p>]]></summary>
</entry>
<entry>
    <title>Thoughts on Clojure vs. Ruby for Startups</title>
    <link href="http://gphil.net/posts/2013-06-07-thoughts-on-clojure-versus-ruby-for-startups.html" />
    <id>http://gphil.net/posts/2013-06-07-thoughts-on-clojure-versus-ruby-for-startups.html</id>
    <published>2013-06-07T00:00:00Z</published>
    <updated>2013-06-07T00:00:00Z</updated>
    <summary type="html"><![CDATA[<p>At <a href="https://kwelia.com">Kwelia</a> we’re building our platform using both Ruby and Clojure. As of today, our web application is a Rails app but we do a lot of backend data processing in Clojure. I personally prefer programming in Clojure to programming in Ruby, and some days I wish we had more Clojure than Ruby in our codebase. I don’t think we’ll be switching from Rails any time soon, but we may try to encapsulate more business logic behind Clojure web services in the future.</p>
<p>When we started building our product (and I still think this is true today–although it’s less true now) it was faster and easier to get a production-ready web application up using Ruby on Rails. One of the best features of Rails in my opinion is that it makes a lot of design decisions for you and that it has pretty sane defaults for the most part. This ends up saving a lot of time up front, which is critical for a start up that wants to quickly validate an idea. There is also a lot of open source code available via RubyGems that replaces or expedites a lot of common web application development tasks. This is a one-two punch that’s pretty hard to beat in a start up context.</p>
<p>However, as the Clojure ecosystem matures it’s starting to chip away at the advantages that the Rails ecosystem offers. More and more quality libraries are being shipped to <a href="https://clojars.org">Clojars</a>, and informal conventions are starting to emerge regarding how to structure a web application in Clojure. I think the growth of both of these are critical for newcomers who want to get started on a Clojure webapp quickly. I’m optimistic that these trends will continue and Clojure will continue to become a better and better choice for new projects.</p>]]></summary>
</entry>
<entry>
    <title>50 Percent Failure Rate</title>
    <link href="http://gphil.net/posts/2013-04-27-50-percent-failure-rate.html" />
    <id>http://gphil.net/posts/2013-04-27-50-percent-failure-rate.html</id>
    <published>2013-04-27T00:00:00Z</published>
    <updated>2013-04-27T00:00:00Z</updated>
    <summary type="html"><![CDATA[<p>Lately I’ve been reading <a href="http://www.amazon.com/gp/product/1935401009/ref=as_li_qf_sp_asin_tl?ie=UTF8&amp;camp=1789&amp;creative=9325&amp;creativeASIN=1935401009&amp;linkCode=as2&amp;tag=gphilsblog-20">The Principles of Product Development Flow</a> by Don Reinertsen. It describes a set of principles for conducting product development in an economically optimal fashion.</p>
<p>The principles in the book are aimed at product development “in the large.” The goal of the book is to empower product developers to make better decisions by quantifying the expected economic value of each decision faced when developing a product.</p>
<p>In my case, I’m developing a software product in a startup context (at <a href="https://kwelia.com">Kwelia</a>) and I’ve found that many of principles described in the book have been helpful in guiding our product development.</p>
<p>One of the principles stood out to me as particularly enlightening for a startup: when running an experiment with two outcomes, a 50% failure rate is optimal for generating information.</p>
<p>That’s because if something is certain to succeed or fail, there’s no reason to test it because you already know. If something is likely to fail, you’ll generate a lot of information if it doesn’t actually fail. But in the majority of instances it will indeed fail, and as such this experiment yields little information.</p>
<p>So, the optimal experiment for generating new information has a 50% failure rate. Programmers might recognize this principle from the binary search algorithm.</p>
<p>This principle underlies a lot of what we should be doing when de-risking startups. Binary questions such as “should we do this or not?” or “will that work?” are constantly arising as we generate new ideas.</p>
<p>Applying this principle, we should try to devise experiments that are much more likely to fail (50%) than we might intuitively think, if we want them to generate as much new information as possible.</p>]]></summary>
</entry>

</feed>
